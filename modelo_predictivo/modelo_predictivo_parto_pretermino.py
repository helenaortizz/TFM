# -*- coding: utf-8 -*-
"""Copy of Modelo Predictivo Parto Pretermino.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TWrITZfpNv-tO6z1ioplJKqgKuI80PXk

# **TFM: MODELO PREDICTIVO DE PARTO PRETÉRMINO USANDO MACHINE LEARNING**

# PASO 1: **CREACIÓN DEL DATASET**

## 1. Preparación del entorno

### 1.1. Carga de librerías
"""

import pandas as pd

"""### 1.2. Carga del archivo de datos original"""

file_path = "/content/drive/MyDrive/Nat2023PublicUS.c20240509.r20240724.txt"

"""## 2. Creación del nuevo dataset

### 2.1. Selección de variables
"""

# Posiciones de las columnas en el dataset
columns_specs = [
    (78, 79),  # MAGER9 - Edad de la madre (recode 9)
    (106, 107),  # MRACE6 - Raza de la madre (recode 6)
    (123, 124),  # MEDUC - Educación de la madre
    (181, 182),  # TBO_REC - Orden total de nacimientos
    (208, 210),  # ILOP_R11 - Intervalo desde el último embarazo
    (226, 227),  # PRECARE5 - Inicio del cuidado prenatal
    (260, 261),  # CIG0_R - Consumo de cigarrillos antes del embarazo
    (286, 287),  # BMI_R - Índice de Masa Corporal (recode)
    (313, 314),  # RF_GDIAB - Diabetes gestacional
    (315, 316),  # RF_GHYPE - Hipertensión gestacional
    (317, 318),  # RF_PPTERM - Parto prematuro previo
    (330, 331),  # RF_CESAR - Cesárea previa
    (336, 337),  # NO_RISKS - Sin factores de riesgo
    (352, 353),  # NO_INFEC - Sin infecciones reportadas
    (386, 387),  # LD_CHOR - Corioamnionitis
    (400, 401),  # ME_PRES - Presentación fetal en el parto
    (453, 454),  # DPLURAL - Pluralidad (gemelos, trillizos, etc.)
    (493, 494)   # GESTREC3 - Duración de la gestación (recode 3)
    ]

# Nombre de las columnas
column_names = [
    "Mother_Age",
    "Mother_Race",
    "Mother_Education",
    "Total_Birth_Order",
    "Interval_Last_Pregnancy",
    "Prenatal_Care_Start",
    "Smoking_Before_Pregnancy",
    "BMI",
    "Gestational_Diabetes",
    "Gestational_Hypertension",
    "Previous_Preterm_Birth",
    "Previous_Cesarean",
    "No_Risk_Factors",
    "No_Infections",
    "Chorioamnionitis",
    "Fetal_Presentation",
    "Plurality",
    "Gestation_Weeks"
    ]

# Lectura del archivo .txt con las posiciones definidas
df = pd.read_fwf(file_path,
                 colspecs=columns_specs,
                 header=None, names=column_names,
                 dtype=str
                 )

"""### 2.2. Creación y guardado del nuevo dataset"""

# Guardado del nuevo dataset en un archivo .CSV
output_file = "/content/parto_pretermino_dataset.csv"
df.to_csv(output_file, index=False)

"""### 2.3. Dimensiones del dataset nuevo"""

print(f'El dataset consta de {df.shape[0]} filas y {df.shape[1]} columnas.')

"""# PASO 2: **ANÁLISIS EXPLORATORIO DE LOS DATOS (EDA)**

## 1. Preparación del entorno

### 1.1. Carga de librerías
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats

"""### 1.2. Formato"""

sns.set(style='whitegrid')

"""### 1.3. Carga del dataset"""

# Carga del nuevo dataset
file_path = '/content/drive/MyDrive/parto_pretermino_dataset.csv'
df = pd.read_csv(file_path)

# Información general del dataset
print(df.info())

"""## 2. Inspección del dataset

### 2.1. Visualización estructura
"""

# Visualización de las primeras filas
print(df.head())

# Número de filas y columnas
print(f'El dataset consta de {df.shape[0]} filas y {df.shape[1]} columnas.')

"""### 2.2. Análisis valores únicos"""

# Análisis de valores únicos en variables categóricas
categorical_cols = ['Gestational_Diabetes', 'Gestational_Hypertension',
                    'Previous_Preterm_Birth','Previous_Cesarean',
                    'Chorioamnionitis', 'Mother_Age', 'Mother_Race',
                    'Mother_Education', 'Total_Birth_Order',
                    'Prenatal_Care_Start', 'BMI', 'No_Risk_Factors',
                    'No_Infections', 'Fetal_Presentation',
                    'Plurality', 'Gestation_Weeks']

for col in categorical_cols:
    print(f'\nValores únicos en {col}:')
    print(df[col].value_counts(dropna=False))

"""### 2.3. Resumen estadístico de las variables"""

# Resumen de variables numéricas
print(df.describe())

# Resumen de variables categóricas
print(df.describe(include=['object', 'category']))

"""## 3. Análisis de valores "U"

### 3.1. Análisis de valores "U" por subgrupos
"""

binary_u_cols = ['Gestational_Diabetes', 'Gestational_Hypertension',
                 'Previous_Preterm_Birth', 'Previous_Cesarean', 'Chorioamnionitis']

subgroups = ['Mother_Race', 'Mother_Age', 'BMI']

for var in binary_u_cols:
    df_u = df[df[var] == 'U']

    for subgroup in subgroups:
        print(f"\nDistribución de 'U' por {subgroup}:")
        print(df_u[subgroup].value_counts(normalize=True).sort_index())

        print(f"\nDistribución general por {subgroup}:")
        print(df[subgroup].value_counts(normalize=True).sort_index())

"""### 3.2. Ajuste de valores"""

# Variables con posibles valores 'U'
binary_u_cols = ['Gestational_Diabetes', 'Gestational_Hypertension',
                 'Previous_Preterm_Birth', 'Previous_Cesarean',
                 'Chorioamnionitis']

# Eliminar filas con al menos un 'U' en esas columnas
df = df[~df[binary_u_cols].isin(['U']).any(axis=1)]

# Verificar tamaño final
print(f"Tamaño tras eliminar 'U': {df.shape}")

"""## 4. Conversión de variables

### 4.1. Variables categóricas
"""

# Definición de mapeos para variables categóricas
age_mapping = {1: '<15', 2: '15-19', 3: '20-24', 4: '25-29', 5: '30-34',
               6: '35-39', 7: '40-44', 8: '45-49', 9: '50-54'}

race_mapping = {1: 'White', 2: 'Black', 3: 'AIAN', 4: 'Asian', 5: 'NHOPI', 6: 'Multiracial'}

education_mapping = {1: '≤8th', 2: '9-12_no_diploma', 3: 'HS_diploma',
                     4: 'Some_college', 5: 'Assoc_degree', 6: 'Bachelor',
                     7: 'Master', 8: 'Doctorate', 9: 'Unknown'}

bmi_mapping = {1: 'Underweight', 2: 'Normal', 3: 'Overweight',
               4: 'Obesity_I', 5: 'Obesity_II', 6: 'Extreme_Obesity', 9: 'Unknown'}

binary_mapping = {'Y': 1, 'N': 0}

# Aplicación de las conversiones
df['Mother_Age'] = df['Mother_Age'].map(age_mapping)
df['Mother_Race'] = df['Mother_Race'].map(race_mapping)
df['Mother_Education'] = df['Mother_Education'].map(education_mapping)
df['BMI'] = df['BMI'].map(bmi_mapping)

"""### 4.2. Variables binarias"""

# Conversión en variables binarias de cara a entrenar el modelo de ML
binary_cols = ['Gestational_Diabetes', 'Gestational_Hypertension',
               'Previous_Preterm_Birth', 'Previous_Cesarean', 'Chorioamnionitis']
for col in binary_cols:
    df[col] = df[col].map(binary_mapping)

# Conversión a category para mayor eficiencia
# Convertir todo lo categórico a dtype category
categorical_cols = ['Mother_Age', 'Mother_Race', 'Mother_Education', 'BMI',
                    'Total_Birth_Order', 'Prenatal_Care_Start',
                    'No_Risk_Factors', 'No_Infections',
                    'Fetal_Presentation', 'Plurality', 'Gestation_Weeks'] + binary_cols

for col in categorical_cols:
    df[col] = df[col].astype('category')

# Eliminar filas con demasiados nulos
df_clean = df.dropna(thresh=len(df.columns) - 2)

"""### 4.3. Visualización de cambios tras los mapeos"""

# Verificación de los cambios
print('\nDatos post conversión:')
print(df.head())
print(df.dtypes)

"""## 5. Manejo de valores nulos

### 5.1. Visualización de valores nulos
"""

# Visualización de valores nulos por columna
missing_values = df.isnull().sum()
print('\nValores nulos por columna:')
print(missing_values)

"""### 5.2. Eliminación de filas"""

# Eliminación de filas con más de 1 valor nulo (si quedan)
df_clean = df.dropna(thresh=df.shape[1] - 1)

"""### 5.3. Visualización tras limpieza"""

# Verificar limpieza
print(f"\nTamaño después de eliminar nulos: {df_clean.shape}")
print("Valores nulos restantes:\n", df_clean.isnull().sum()[df_clean.isnull().sum() > 0])

"""## 6. Definición de la variable objetivo"""

# Conversión de la la variable objetivo
gestation_mapping = {1: 1, 2: 0, 3: None}
df_clean['Gestation_Weeks'] = df_clean['Gestation_Weeks'].map(gestation_mapping)

# Eliminación de filas con valor desconocido si existen
df_clean = df_clean.dropna(subset=['Gestation_Weeks'])

# Verificación de la distribución de la variable objetivo
print('\nDistribución de la variable objetivo:')
print(df_clean['Gestation_Weeks'].value_counts(normalize=True))

"""## 7. Distribución de las variables

### 7.1. Variables categóricas
"""

# Visualización de la distribución de las variables categóricas
categorical_cols = df_clean.select_dtypes(include=['category']).columns
num_cols = len(categorical_cols)
rows = (num_cols // 3) + (num_cols % 3 > 0)

plt.figure(figsize=(15, rows * 4))

for i, col in enumerate(categorical_cols, 1):
    plt.subplot(rows, 3, i)
    sns.countplot(x=col, data=df_clean, hue='Gestation_Weeks')
    plt.xticks(rotation=45)
    plt.title(f'Distribución de {col}')

plt.tight_layout()
plt.show()

"""### 7.2. Variables numéricas"""

# Visualización de la distribución para variables numéricas
numeric_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns
num_cols = len(numeric_cols)
rows = (num_cols // 3) + (num_cols % 3 > 0)

plt.figure(figsize=(15, rows * 4))

for i, col in enumerate(numeric_cols, 1):
    plt.subplot(rows, 3, i)
    sns.histplot(df_clean[col].dropna(), bins=15)
    plt.title(f'Distribución de {col}')

plt.tight_layout()
plt.show()

"""## 8. Análisis de correlaciones

### 8.1. Correlación entre variables numéricas (Coeficiente de Pearson)
"""

# Matriz de correlación
corr_matrix = df_clean[numeric_cols].corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1,
            vmax=1, linewidths=0.5, cbar_kws={'shrink': 0.8})
plt.title('Matriz de Correlación', fontsize=16)
plt.tight_layout()
plt.show()

"""### 8.2. Correlación entre variables categóricas (V de Cramer)"""

# Definición de la función para calcular la V de Cramer
def cramers_v(x, y):
    confusion_matrix = pd.crosstab(x, y)
    chi2 = stats.chi2_contingency(confusion_matrix, correction=False)[0]
    n = confusion_matrix.sum().sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    return np.sqrt(phi2 / min(k - 1, r - 1))

# Selección de variables categóricas
cat_cols = df_clean.select_dtypes(include='category').columns.tolist()

# Matriz de V de Cramer
cramer_matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)

for col1 in cat_cols:
    for col2 in cat_cols:
        if col1 == col2:
            cramer_matrix.loc[col1, col2] = 1.0
        else:
            cramer_matrix.loc[col1, col2] = cramers_v(df_clean[col1], df_clean[col2])

cramer_matrix = cramer_matrix.astype(float)

# Visualización
plt.figure(figsize=(14, 12))
sns.heatmap(cramer_matrix, annot=False, cmap="YlGnBu", vmin=0, vmax=1, linewidths=0.5)
plt.title("Matriz de asociación entre variables categóricas (Cramér's V)", fontsize=16)
plt.tight_layout()
plt.show()

"""### 8.3. Correlación entre variables categóricas y numéricas (ANOVA)"""

# Función para calcular eta²
def eta_squared(categorical, numerical):
    categories = df_clean[categorical].dropna().unique()
    means = []
    counts = []

    for cat in categories:
        group = df_clean[df_clean[categorical] == cat][numerical].dropna()
        means.append(group.mean())
        counts.append(len(group))

    overall_mean = df_clean[numerical].dropna().mean()
    ss_between = sum(counts[i] * (means[i] - overall_mean)**2 for i in range(len(categories)))
    ss_total = sum((x - overall_mean)**2 for x in df_clean[numerical].dropna())

    return ss_between / ss_total if ss_total != 0 else np.nan

# Lista de variables categóricas y numéricas
numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_cols = df_clean.select_dtypes(include='category').columns.tolist()

# Cálculo de eta²
eta2_matrix = pd.DataFrame(index=cat_cols, columns=numeric_cols)

for cat in cat_cols:
    for num in numeric_cols:
        eta2_matrix.loc[cat, num] = eta_squared(cat, num)

eta2_matrix = eta2_matrix.astype(float)

# Visualización
plt.figure(figsize=(14, 12))
sns.heatmap(eta2_matrix, annot=False, cmap="Purples", vmin=0, vmax=1, linewidths=0.5)
plt.title("Asociación entre variables categóricas y numéricas (eta²)", fontsize=16)
plt.tight_layout()
plt.show()

"""# PASO 3: **CREACIÓN DEL MODELO PREDICTIVO**"""

# Manipulación de datos
import numpy as np
import pandas as pd

# Visualización
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# Preprocesamiento
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# División y validación de datos
from sklearn.model_selection import (
    train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
)

# Clasificadores
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBClassifier
from scipy.stats import uniform, randint

# Métricas
from sklearn.metrics import (
    recall_score, make_scorer, classification_report,
    confusion_matrix, roc_auc_score, roc_curve, auc
)
from scipy.stats import uniform, randint

# Manejo de clases desbalanceadas
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import SMOTE

# Guardado de modelos
import joblib

"""## 2. División del dataset y preprocesamiento

### 2.1. División en train y test

Estratificada para respetar la proporción de clases
"""

# Separación var objetivo
X = df_clean.drop(columns=['Gestation_Weeks'])
y = df_clean['Gestation_Weeks']

# División en train/test (estratificada para respetar proporción de clases)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Identificación de columnas categóricas y numéricas
categorical_cols = X.select_dtypes(include=['category']).columns.tolist()
numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

"""### 2.2. Visualización"""

print("Columnas categóricas:", categorical_cols)
print("Columnas numéricas:", numeric_cols)

"""### 2.3. Preprocesamiento de los datos"""

# Preprocesamiento para columnas numéricas
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),  # Si quedan NaNs
    ('scaler', StandardScaler())
])

# Preprocesamiento para columnas categóricas
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# Combinación de ambos
preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_cols),
    ('cat', categorical_transformer, categorical_cols)
])

"""### 2.4. Función para evaluar los modelos"""

def evaluar_modelo(modelo, X_test, y_test, nombre_modelo="Modelo"):
    y_pred = modelo.predict(X_test)
    y_proba = modelo.predict_proba(X_test)[:, 1]

    print(f"\n== Evaluación de {nombre_modelo} en test ==")
    print(classification_report(y_test, y_pred, digits=4))
    print(f"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}")

    # Matriz de confusión
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Matriz de confusión - {nombre_modelo}")
    plt.xlabel("Predicción")
    plt.ylabel("Real")
    plt.show()

    # Curva ROC
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{nombre_modelo} (AUC = {roc_auc:.2f})")
    plt.plot([0, 1], [0, 1], linestyle="--")
    plt.xlabel("Tasa de falsos positivos")
    plt.ylabel("Tasa de verdaderos positivos")
    plt.title(f"Curva ROC - {nombre_modelo}")
    plt.legend()
    plt.show()

"""## 3. Modelos predictivos

## 3.1. Regresión Logística
"""

# Creacion del pipeline completo: preprocesamiento + modelo
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000))
])

# Definición de la métrica de evaluación (recall)
recall = make_scorer(recall_score)

# Validación cruzada estratificada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Evaluación
cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=cv, scoring=recall)

print(f"Recall en validación cruzada (5 folds): {cv_scores.mean():.4f}")

# Entrenamiento completo y evaluación en test
model_pipeline.fit(X_train, y_train)
evaluar_modelo(model_pipeline, X_test, y_test, "Regresión Logística")

"""#### 3.1.1. Aplicación de Undersampling"""

# Antes de hacer undersampling, combinación X_train e y_train
rus = RandomUnderSampler(random_state=42)

X_train_under, y_train_under = rus.fit_resample(X_train, y_train)

# Comprobación de la nueva distribución de clases
print("Distribución tras undersampling:")
print(y_train_under.value_counts())

# Entrenamiento del pipeline completo con los datos submuestreados
cv_scores_under = cross_val_score(model_pipeline, X_train_under, y_train_under, cv=cv, scoring=recall)

print(f"Recall tras undersampling (media de 5 folds): {cv_scores_under.mean():.4f}")

"""##3.2. XG-Boost"""

# Cálculo del peso de clase
neg, pos = y_train.value_counts()
scale_pos_weight = neg / pos

# Modelo base
xgb_model = XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False,
    random_state=42,
    n_jobs=-1
)

# Pipeline
xgb_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', xgb_model)
])

# Mantenemos 4 combinaciones
param_grid = {
    'classifier__n_estimators': [100],
    'classifier__max_depth': [3, 5],
    'classifier__learning_rate': [0.1],
    'classifier__scale_pos_weight': [scale_pos_weight],
}

# GridSearchCV
grid_search = GridSearchCV(
    xgb_pipeline,
    param_grid,
    cv=cv,
    scoring=recall,
    n_jobs=-1,
    verbose=1
)

# Entrenamiento
grid_search.fit(X_train, y_train)

print("Mejores parámetros (XGBoost):", grid_search.best_params_)
print(f"Mejor recall CV (XGBoost): {grid_search.best_score_:.4f}")

# Evaluación en test
mejor_xgb = grid_search.best_estimator_
evaluar_modelo(mejor_xgb, X_test, y_test, "XGBoost")

"""## 3.3. Árbol de Decisión (Decision Tree)"""

# Pipeline para Árbol de Decisión
dt_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(
        class_weight='balanced',
        random_state=42,
        max_depth=10,
        min_samples_leaf=50
    ))
])

# Validación cruzada
dt_scores = cross_val_score(dt_pipeline, X_train, y_train, cv=cv, scoring=recall)
print(f"Recall árbol de decisión (CV): {dt_scores.mean():.4f}")

# Entrenamiento y evaluación en test
dt_pipeline.fit(X_train, y_train)
evaluar_modelo(dt_pipeline, X_test, y_test, "Árbol de Decisión")

"""## 3.4. Random Forest"""

rf_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(
        class_weight='balanced',
        random_state=42,
        n_estimators=25,
        max_depth=10,
        max_features='sqrt',
        n_jobs=-1
    ))
])

# Validación cruzada
rf_scores = cross_val_score(rf_pipeline, X_train, y_train, cv=cv, scoring=recall)
print(f"Recall validación cruzada (Random Forest): {rf_scores.mean():.4f}")

# Entrenamiento y evaluación en test
rf_pipeline.fit(X_train, y_train)
evaluar_modelo(rf_pipeline, X_test, y_test, "Random Forest")

"""## 3.5. Comparación de modelos"""

print("Resumen de Recall en validación cruzada:")
print(f"- Regresión Logística: {cv_scores.mean():.4f}")
print(f"- Árbol de Decisión: {dt_scores.mean():.4f}")
print(f"- XGBoost: {grid_search.best_score_:.4f}")
print(f"- Random Forest: {rf_scores.mean():.4f}")

"""## 3.6. Mejora de XGBoost

#### 3.6.1. Recálculo del peso de clase
"""

# Calcular proporción clases
neg, pos = y_train.value_counts()
scale_pos_weight = neg / pos
print(f"Proporción clases (neg:pos): {scale_pos_weight:.2f}")

"""#### 3.6.2. Definición del modelo base"""

xgb_model = XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False,
    random_state=42,
    n_jobs=-1,
    scale_pos_weight=scale_pos_weight
)

"""#### 3.6.3. Creación pipeline con preprocesamiento"""

# Pipeline nuevo completo con: preprocesamiento,SMOTE y modelo

# Preprocesamiento numérico
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Preprocesamiento categórico
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# Combinar ambos
preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_cols),
    ('cat', categorical_transformer, categorical_cols)
])

# Pipeline final
xgb_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', xgb_model)
])

"""#### 3.6.4. Búsqueda de hiperparámetros con RandomizedSearchCV"""

param_dist = {
    'classifier__n_estimators': randint(50, 120),
    'classifier__max_depth': randint(3, 7),
    'classifier__learning_rate': uniform(0.05, 0.1),
    'classifier__scale_pos_weight': uniform(scale_pos_weight * 0.9, scale_pos_weight * 0.2)
}

"""#### 3.6.5. Búsqueda aleatoria de hiperparámetros


"""

# Validación cruzada estratificada
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
recall = make_scorer(recall_score)

# Búsqueda aleatoria
random_search = RandomizedSearchCV(
    xgb_pipeline,
    param_distributions=param_dist,
    n_iter=10,
    cv=cv,
    scoring=recall,
    n_jobs=-1,
    verbose=1,
    random_state=42
)

"""#### 3.6.6. Entrenamiento del modelo optimizado"""

random_search.fit(X_train, y_train)

"""#### 3.6.7. Evaluación del mejor modelo"""

# Resultados de la búsqueda
print("Mejores parámetros (XGBoost):", random_search.best_params_)
print(f"Mejor recall CV (XGBoost): {random_search.best_score_:.4f}")

# Evaluación en test
mejor_xgb = random_search.best_estimator_
evaluar_modelo(mejor_xgb, X_test, y_test, "XGBoost Optimizado")

"""#### 3.6.8. Evaluación modelo base con modelo optimizado"""

# Entrenar modelo base (sin búsqueda de hiperparámetros)
xgb_base = xgb_pipeline
xgb_base.fit(X_train, y_train)

# Probabilidades
y_proba_base = xgb_base.predict_proba(X_test)[:, 1]
y_proba_opt = mejor_xgb.predict_proba(X_test)[:, 1]

# Curvas ROC
from sklearn.metrics import roc_curve, auc
fpr_base, tpr_base, _ = roc_curve(y_test, y_proba_base)
fpr_opt, tpr_opt, _ = roc_curve(y_test, y_proba_opt)
auc_base = auc(fpr_base, tpr_base)
auc_opt = auc(fpr_opt, tpr_opt)

# Gráfico
plt.figure(figsize=(8, 6))
plt.plot(fpr_base, tpr_base, label=f"XGBoost base (AUC = {auc_base:.2f})", linestyle='--')
plt.plot(fpr_opt, tpr_opt, label=f"XGBoost optimizado (AUC = {auc_opt:.2f})", linewidth=2)
plt.plot([0, 1], [0, 1], linestyle="--", color='gray')
plt.xlabel("Tasa de falsos positivos")
plt.ylabel("Tasa de verdaderos positivos")
plt.title("Curva ROC - Comparación de modelos XGBoost")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""#### 3.6.9. Interpretación del modelo con SHAP"""

# Extraer modelo entrenado
modelo_final = mejor_xgb.named_steps['classifier']

# Preprocesar X_test (sin pipeline completo)
X_test_preprocessed = mejor_xgb.named_steps['preprocessor'].transform(X_test)

# Explainer
explainer = shap.Explainer(modelo_final)
shap_values = explainer(X_test_preprocessed)

# Visualización global
shap.summary_plot(shap_values, X_test_preprocessed,
                  feature_names=mejor_xgb.named_steps['preprocessor'].get_feature_names_out())

"""#### 3.6.10. Guardado del modelo"""

joblib.dump(mejor_xgb, 'mejor_modelo_xgboost.pkl')